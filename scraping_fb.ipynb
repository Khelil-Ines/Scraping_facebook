from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from bs4 import BeautifulSoup
import time
import pandas as pd

auteurs=[]
comment_texts=[] 
dates=[]

#Ignorer les notifications du navigateur
chrome_options = webdriver.ChromeOptions()
prefs = {"profile.default_content_setting_values.notifications" : 2}
chrome_options.add_experimental_option("prefs",prefs)


#Specifier le chemin vers chromedriver.exe (déja téléchargé sur notre machine)
driver = webdriver.Chrome(r"C:\Users\TINKPAD\anaconda3\chromedriver.exe",chrome_options=chrome_options)
#open the webpage
driver.get("http://www.facebook.com")

#target username
username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "input[name='email']")))
password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "input[name='pass']")))

#enter username and password
username.clear()
username.send_keys("*****")
password.clear()
password.send_keys("*****")

#target the login button and click it
button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button[type='submit']"))).click()
driver.get("********")

#We are logged in!
names=[]
#program to parse comments from 5 pages, if you want comments from all pages then use while loop
#url="http://mbasic.facebook.com/*****"
#url=("https://mbasic.facebook.com/******")
#url=url+str(cnt)
cnt=0
for i in range(1):
    url="https://mbasic.facebook.com/*******"+str(cnt)
    driver.get(url)
    content = driver.page_source # télécharger le code source de la page
    soup = BeautifulSoup(content,'html5lib') # définir la nature de code a parser ou analyser : html5 avec bs4
    for div in soup.findAll('div', attrs={'class':'_2vj7 _2phz acw apl'}): # parcouris tout les commentaires
        #print(div)
        auteur=div.find('a', attrs={'class':'actor'})
        comment_text=""
       
        date=div.find('abbr')
        try:
            auteurs.append(auteur.text)
            print(auteur.text)
        except Exception :
            auteurs.append(auteur)
        try:
            comment_texts.append(comment_text.text)
            print(comment_text.text)
        except Exception:
            comment_texts.append(comment_text)
        try:
            dates.append(date.text)
            print(date.text)
        except Exception:
            dates.append(date)
    cnt=cnt+10  
genre = '***'
marque = '****'
df = pd.DataFrame({'Date':dates,'Comment Text':comment_texts,'Author':auteurs, 'Genre':genre, 'Url':url, 'Marque':marque}) 
df.to_csv('*****.csv', index=False, encoding='utf-8-sig',sep=';')
driver.close()
